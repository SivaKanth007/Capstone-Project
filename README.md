# ğŸ­ Smart Industrial Maintenance System

> **FSE 570 Data Science Capstone** â€” Arizona State University

An end-to-end AI system that detects anomalies in industrial sensors, predicts machine failures, and generates optimized maintenance schedules.

## ğŸ‘¥ Team

| Name | Role |
|------|------|
| Anoushka Jaydas Dighe | Team Member |
| Deva Siva Kanth Tavvala | Team Member |
| Mohit Kumar Petla | Team Member |
| Umang Rajnikant Bid | Team Member |
| Urvansh Jignesh Shah | Team Member |

---

## ğŸš€ Quick Start (Fresh Install)

### Step 1 â€” Clone the Repository

```bash
git clone https://github.com/<your-username>/Capstone-Project.git
cd Capstone-Project
```

### Step 2 â€” Install Dependencies

```bash
pip install -r requirements.txt
```

> **Requires Python 3.9 or higher.**  
> No GPU needed â€” everything runs on CPU. GPU (CUDA) is auto-detected if available.

### Step 3 â€” Train All Models

```bash
python scripts/train_all.py
```

This single command does everything:
- Downloads the NASA C-MAPSS turbofan dataset automatically
- Generates synthetic maintenance logs
- Engineers 200+ features from sensor data
- Trains 4 ML models (LSTM Autoencoder, LSTM Predictor, XGBoost, Bayesian Survival)
- Runs Monte Carlo simulation comparing maintenance policies

**â± Takes ~5 minutes on CPU.**

### Step 4 â€” Run Inference Pipeline

```bash
python scripts/run_pipeline.py
```

Loads the trained models and produces maintenance recommendations saved to `data/processed/recommendations.csv`.

### Step 5 â€” Launch Dashboard

```bash
streamlit run dashboard/app.py
```

Opens at **http://localhost:8501** in your browser.

### Step 6 â€” Run Tests

```bash
python -m pytest
```

All 27 unit tests should pass.

---

## ğŸ“Š What This System Does

```
Raw Sensor Data â†’ Preprocessing â†’ ML Models â†’ MILP Optimizer â†’ Dashboard
```

| Component | What It Does |
|-----------|-------------|
| **Anomaly Detection** | LSTM Autoencoder flags unusual sensor patterns |
| **Failure Prediction** | LSTM Classifier estimates failure probability (next 30 cycles) |
| **RUL Estimation** | XGBoost predicts Remaining Useful Life in cycles |
| **Uncertainty** | Bayesian Weibull model gives 90%/95% confidence intervals |
| **Scheduling** | MILP optimizer assigns maintenance to crews optimally |
| **Dashboard** | Streamlit app shows live fleet health and schedule |

---

## ğŸ“ˆ Results

| Model | Metric | Value |
|-------|--------|-------|
| LSTM Failure Predictor | F1-Score | **0.933** |
| LSTM Failure Predictor | AUC-ROC | **0.997** |
| XGBoost RUL | RMSE | **10.48 cycles** |
| XGBoost RUL | RÂ² | **0.937** |
| Bayesian Survival | C-Index | **0.992** |
| MILP Optimization | Cost Reduction | **97.4%** vs reactive |
| MILP Optimization | Downtime Reduction | **72.4%** vs reactive |

---

## ğŸ“ Project Structure

```
Capstone-Project/
â”œâ”€â”€ config.py                    # All settings (paths, hyperparameters)
â”œâ”€â”€ requirements.txt             # Python dependencies
â”œâ”€â”€ pytest.ini                   # Test configuration
â”œâ”€â”€ PROJECT_REPORT.md            # Full project report
â”‚
â”œâ”€â”€ scripts/
â”‚   â”œâ”€â”€ train_all.py             # â† Run this first to train all models
â”‚   â””â”€â”€ run_pipeline.py          # â† Run this to get predictions
â”‚
â”œâ”€â”€ dashboard/
â”‚   â””â”€â”€ app.py                   # â† Streamlit dashboard
â”‚
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ data/                    # Data download, preprocessing, features
â”‚   â”œâ”€â”€ models/                  # LSTM, XGBoost, Bayesian Survival models
â”‚   â”œâ”€â”€ explainability/          # SHAP + attention visualization
â”‚   â”œâ”€â”€ optimization/            # MILP maintenance scheduler
â”‚   â””â”€â”€ evaluation/              # Monte Carlo simulation
â”‚
â”œâ”€â”€ tests/                       # 27 unit tests
â”œâ”€â”€ notebooks/                   # Google Colab notebook (GPU version)
â”‚
â”œâ”€â”€ data/                        # Created automatically after training
â”‚   â”œâ”€â”€ raw/                     # Downloaded NASA C-MAPSS dataset
â”‚   â”œâ”€â”€ processed/               # Preprocessed sequences
â”‚   â””â”€â”€ synthetic/               # Generated maintenance logs
â”‚
â”œâ”€â”€ models/saved/                # Trained model files (created after training)
â”‚   â”œâ”€â”€ autoencoder.pt
â”‚   â”œâ”€â”€ lstm_predictor.pt
â”‚   â”œâ”€â”€ xgboost_rul.pkl
â”‚   â”œâ”€â”€ bayesian_survival.pkl
â”‚   â””â”€â”€ preprocessor.pkl
â”‚
â””â”€â”€ assets/                      # Dashboard screenshots
```

---

## âš¡ GPU Support

The system automatically uses a CUDA GPU if available:

```python
# config.py â€” detected automatically
DEVICE = torch.device("cuda" if torch.cuda.is_available() else "cpu")
```

For Google Colab with free GPU, open `notebooks/capstone_colab.ipynb`.

---

## ğŸ”´ğŸŸ¡ğŸŸ¢ Risk Levels

| Level | Condition | Action |
|-------|-----------|--------|
| ğŸ”´ Critical | Risk â‰¥ 70% | Service Immediately |
| ğŸŸ¡ Elevated | Risk 40â€“70% | Schedule Soon |
| ğŸŸ¢ Normal | Risk < 40% | Continue Monitoring |

---

## ğŸ›  Troubleshooting

| Problem | Fix |
|---------|-----|
| `ModuleNotFoundError` | Run `pip install -r requirements.txt` again |
| `No data found` | Run `python scripts/train_all.py` first |
| Dashboard blank | Make sure `run_pipeline.py` has been run |
| Tests not found | Run `python -m pytest` from the project root |

---

## ğŸ“„ License

Developed for FSE 570 at Arizona State University.
