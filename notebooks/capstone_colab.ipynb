{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# üè≠ Smart Industrial Maintenance System ‚Äî GPU Training Notebook\n",
                "\n",
                "**FSE 570 Capstone** | Arizona State University\n",
                "\n",
                "This notebook runs the complete training pipeline on Google Colab with GPU acceleration.\n",
                "\n",
                "---"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 1. Setup Environment"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 1,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "PyTorch: 2.10.0+cu128\n",
                        "CUDA available: True\n",
                        "GPU: NVIDIA L4\n",
                        "VRAM: 23.7 GB\n"
                    ]
                }
            ],
            "source": [
                "# Check GPU availability\n",
                "import torch\n",
                "print(f\"PyTorch: {torch.__version__}\")\n",
                "print(f\"CUDA available: {torch.cuda.is_available()}\")\n",
                "if torch.cuda.is_available():\n",
                "    print(f\"GPU: {torch.cuda.get_device_name(0)}\")\n",
                "    props = torch.cuda.get_device_properties(0)\n",
                "    vram = getattr(props, 'total_memory', getattr(props, 'total_mem', 0))\n",
                "    print(f\"VRAM: {vram / 1e9:.1f} GB\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 2,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
                        "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m350.0/350.0 kB\u001b[0m \u001b[31m29.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
                        "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m117.3/117.3 kB\u001b[0m \u001b[31m13.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
                        "\u001b[?25h  Building wheel for autograd-gamma (setup.py) ... \u001b[?25l\u001b[?25hdone\n"
                    ]
                }
            ],
            "source": [
                "# Install dependencies\n",
                "!pip install -q xgboost lifelines shap pulp"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 3,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Cloning into 'Capstone-Project'...\n",
                        "remote: Enumerating objects: 55, done.\u001b[K\n",
                        "remote: Counting objects: 100% (55/55), done.\u001b[K\n",
                        "remote: Compressing objects: 100% (37/37), done.\u001b[K\n",
                        "remote: Total 55 (delta 9), reused 54 (delta 8), pack-reused 0 (from 0)\u001b[K\n",
                        "Receiving objects: 100% (55/55), 826.59 KiB | 907.00 KiB/s, done.\n",
                        "Resolving deltas: 100% (9/9), done.\n",
                        "/content/Capstone-Project\n"
                    ]
                }
            ],
            "source": [
                "# Clone your project repo\n",
                "!git clone https://github.com/SivaKanth007/Capstone-Project.git\n",
                "%cd Capstone-Project"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 2. Download & Preprocess Data\n",
                "\n",
                "The download module will automatically try direct download first ‚Äî **no Kaggle credentials needed**.\n",
                "If the direct download fails, it falls back to a synthetic data generator."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 4,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "[CONFIG] Using device: cuda\n",
                        "[CONFIG] GPU: NVIDIA L4\n",
                        "[CONFIG] VRAM: 23.7 GB\n",
                        "[DOWNLOAD] Attempting direct download (no authentication required)...\n",
                        "[DOWNLOAD] Downloading from: https://phm-datasets.s3.amazonaws.com/NASA/6.+Turbofan+Engine+Degradation+Simula...\n",
                        "[DOWNLOAD] Progress: 100% (12.4 MB)\n",
                        "[DOWNLOAD] Extracting...\n",
                        "[DOWNLOAD] Extracting nested zip: CMAPSSData.zip\n",
                        "[DOWNLOAD] Direct download successful!\n",
                        "[DOWNLOAD] Available files:\n",
                        "  - Damage Propagation Modeling.pdf (0.43 MB)\n",
                        "  - RUL_FD001.txt (0.00 MB)\n",
                        "  - RUL_FD002.txt (0.00 MB)\n",
                        "  - RUL_FD003.txt (0.00 MB)\n",
                        "  - RUL_FD004.txt (0.00 MB)\n",
                        "  - readme.txt (0.00 MB)\n",
                        "  - test_FD001.txt (2.23 MB)\n",
                        "  - test_FD002.txt (5.73 MB)\n",
                        "  - test_FD003.txt (2.83 MB)\n",
                        "  - test_FD004.txt (6.96 MB)\n",
                        "  - train_FD001.txt (3.52 MB)\n",
                        "  - train_FD002.txt (9.08 MB)\n",
                        "  - train_FD003.txt (4.21 MB)\n",
                        "  - train_FD004.txt (10.35 MB)\n",
                        "[DOWNLOAD] Loading training data from: /content/Capstone-Project/data/raw/train_FD001.txt\n",
                        "[DOWNLOAD] Loaded 20631 rows, 100 units\n",
                        "[DOWNLOAD] Cycle range: 1 - 362\n",
                        "[DOWNLOAD] RUL range: 0 - 125\n",
                        "\n",
                        "Training data: (20631, 27)\n"
                    ]
                },
                {
                    "data": {
                        "text/html": [
                            "\n",
                            "  <div id=\"df-e3e19074-e789-4c2c-a690-c5cae5ab860e\" class=\"colab-df-container\">\n",
                            "    <div>\n",
                            "<style scoped>\n",
                            "    .dataframe tbody tr th:only-of-type {\n",
                            "        vertical-align: middle;\n",
                            "    }\n",
                            "\n",
                            "    .dataframe tbody tr th {\n",
                            "        vertical-align: top;\n",
                            "    }\n",
                            "\n",
                            "    .dataframe thead th {\n",
                            "        text-align: right;\n",
                            "    }\n",
                            "</style>\n",
                            "<table border=\"1\" class=\"dataframe\">\n",
                            "  <thead>\n",
                            "    <tr style=\"text-align: right;\">\n",
                            "      <th></th>\n",
                            "      <th>unit_id</th>\n",
                            "      <th>cycle</th>\n",
                            "      <th>op_setting_1</th>\n",
                            "      <th>op_setting_2</th>\n",
                            "      <th>op_setting_3</th>\n",
                            "      <th>sensor_1</th>\n",
                            "      <th>sensor_2</th>\n",
                            "      <th>sensor_3</th>\n",
                            "      <th>sensor_4</th>\n",
                            "      <th>sensor_5</th>\n",
                            "      <th>...</th>\n",
                            "      <th>sensor_13</th>\n",
                            "      <th>sensor_14</th>\n",
                            "      <th>sensor_15</th>\n",
                            "      <th>sensor_16</th>\n",
                            "      <th>sensor_17</th>\n",
                            "      <th>sensor_18</th>\n",
                            "      <th>sensor_19</th>\n",
                            "      <th>sensor_20</th>\n",
                            "      <th>sensor_21</th>\n",
                            "      <th>RUL</th>\n",
                            "    </tr>\n",
                            "  </thead>\n",
                            "  <tbody>\n",
                            "    <tr>\n",
                            "      <th>0</th>\n",
                            "      <td>1</td>\n",
                            "      <td>1</td>\n",
                            "      <td>-0.0007</td>\n",
                            "      <td>-0.0004</td>\n",
                            "      <td>100.0</td>\n",
                            "      <td>518.67</td>\n",
                            "      <td>641.82</td>\n",
                            "      <td>1589.70</td>\n",
                            "      <td>1400.60</td>\n",
                            "      <td>14.62</td>\n",
                            "      <td>...</td>\n",
                            "      <td>2388.02</td>\n",
                            "      <td>8138.62</td>\n",
                            "      <td>8.4195</td>\n",
                            "      <td>0.03</td>\n",
                            "      <td>392</td>\n",
                            "      <td>2388</td>\n",
                            "      <td>100.0</td>\n",
                            "      <td>39.06</td>\n",
                            "      <td>23.4190</td>\n",
                            "      <td>125</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>1</th>\n",
                            "      <td>1</td>\n",
                            "      <td>2</td>\n",
                            "      <td>0.0019</td>\n",
                            "      <td>-0.0003</td>\n",
                            "      <td>100.0</td>\n",
                            "      <td>518.67</td>\n",
                            "      <td>642.15</td>\n",
                            "      <td>1591.82</td>\n",
                            "      <td>1403.14</td>\n",
                            "      <td>14.62</td>\n",
                            "      <td>...</td>\n",
                            "      <td>2388.07</td>\n",
                            "      <td>8131.49</td>\n",
                            "      <td>8.4318</td>\n",
                            "      <td>0.03</td>\n",
                            "      <td>392</td>\n",
                            "      <td>2388</td>\n",
                            "      <td>100.0</td>\n",
                            "      <td>39.00</td>\n",
                            "      <td>23.4236</td>\n",
                            "      <td>125</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>2</th>\n",
                            "      <td>1</td>\n",
                            "      <td>3</td>\n",
                            "      <td>-0.0043</td>\n",
                            "      <td>0.0003</td>\n",
                            "      <td>100.0</td>\n",
                            "      <td>518.67</td>\n",
                            "      <td>642.35</td>\n",
                            "      <td>1587.99</td>\n",
                            "      <td>1404.20</td>\n",
                            "      <td>14.62</td>\n",
                            "      <td>...</td>\n",
                            "      <td>2388.03</td>\n",
                            "      <td>8133.23</td>\n",
                            "      <td>8.4178</td>\n",
                            "      <td>0.03</td>\n",
                            "      <td>390</td>\n",
                            "      <td>2388</td>\n",
                            "      <td>100.0</td>\n",
                            "      <td>38.95</td>\n",
                            "      <td>23.3442</td>\n",
                            "      <td>125</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>3</th>\n",
                            "      <td>1</td>\n",
                            "      <td>4</td>\n",
                            "      <td>0.0007</td>\n",
                            "      <td>0.0000</td>\n",
                            "      <td>100.0</td>\n",
                            "      <td>518.67</td>\n",
                            "      <td>642.35</td>\n",
                            "      <td>1582.79</td>\n",
                            "      <td>1401.87</td>\n",
                            "      <td>14.62</td>\n",
                            "      <td>...</td>\n",
                            "      <td>2388.08</td>\n",
                            "      <td>8133.83</td>\n",
                            "      <td>8.3682</td>\n",
                            "      <td>0.03</td>\n",
                            "      <td>392</td>\n",
                            "      <td>2388</td>\n",
                            "      <td>100.0</td>\n",
                            "      <td>38.88</td>\n",
                            "      <td>23.3739</td>\n",
                            "      <td>125</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>4</th>\n",
                            "      <td>1</td>\n",
                            "      <td>5</td>\n",
                            "      <td>-0.0019</td>\n",
                            "      <td>-0.0002</td>\n",
                            "      <td>100.0</td>\n",
                            "      <td>518.67</td>\n",
                            "      <td>642.37</td>\n",
                            "      <td>1582.85</td>\n",
                            "      <td>1406.22</td>\n",
                            "      <td>14.62</td>\n",
                            "      <td>...</td>\n",
                            "      <td>2388.04</td>\n",
                            "      <td>8133.80</td>\n",
                            "      <td>8.4294</td>\n",
                            "      <td>0.03</td>\n",
                            "      <td>393</td>\n",
                            "      <td>2388</td>\n",
                            "      <td>100.0</td>\n",
                            "      <td>38.90</td>\n",
                            "      <td>23.4044</td>\n",
                            "      <td>125</td>\n",
                            "    </tr>\n",
                            "  </tbody>\n",
                            "</table>\n",
                            "<p>5 rows √ó 27 columns</p>\n",
                            "</div>\n",
                            "    <div class=\"colab-df-buttons\">\n",
                            "      \n",
                            "  <div class=\"colab-df-container\">\n",
                            "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-e3e19074-e789-4c2c-a690-c5cae5ab860e')\"\n",
                            "            title=\"Convert this dataframe to an interactive table.\"\n",
                            "            style=\"display:none;\">\n",
                            "      \n",
                            "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
                            "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
                            "  </svg>\n",
                            "    </button>\n",
                            "    \n",
                            "  <style>\n",
                            "    .colab-df-container {\n",
                            "      display:flex;\n",
                            "      gap: 12px;\n",
                            "    }\n",
                            "\n",
                            "    .colab-df-convert {\n",
                            "      background-color: #E8F0FE;\n",
                            "      border: none;\n",
                            "      border-radius: 50%;\n",
                            "      cursor: pointer;\n",
                            "      display: none;\n",
                            "      fill: #1967D2;\n",
                            "      height: 32px;\n",
                            "      padding: 0 0 0 0;\n",
                            "      width: 32px;\n",
                            "    }\n",
                            "\n",
                            "    .colab-df-convert:hover {\n",
                            "      background-color: #E2EBFA;\n",
                            "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
                            "      fill: #174EA6;\n",
                            "    }\n",
                            "\n",
                            "    .colab-df-buttons div {\n",
                            "      margin-bottom: 4px;\n",
                            "    }\n",
                            "\n",
                            "    [theme=dark] .colab-df-convert {\n",
                            "      background-color: #3B4455;\n",
                            "      fill: #D2E3FC;\n",
                            "    }\n",
                            "\n",
                            "    [theme=dark] .colab-df-convert:hover {\n",
                            "      background-color: #434B5C;\n",
                            "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
                            "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
                            "      fill: #FFFFFF;\n",
                            "    }\n",
                            "  </style>\n",
                            "\n",
                            "    <script>\n",
                            "      const buttonEl =\n",
                            "        document.querySelector('#df-e3e19074-e789-4c2c-a690-c5cae5ab860e button.colab-df-convert');\n",
                            "      buttonEl.style.display =\n",
                            "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
                            "\n",
                            "      async function convertToInteractive(key) {\n",
                            "        const element = document.querySelector('#df-e3e19074-e789-4c2c-a690-c5cae5ab860e');\n",
                            "        const dataTable =\n",
                            "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
                            "                                                    [key], {});\n",
                            "        if (!dataTable) return;\n",
                            "\n",
                            "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
                            "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
                            "          + ' to learn more about interactive tables.';\n",
                            "        element.innerHTML = '';\n",
                            "        dataTable['output_type'] = 'display_data';\n",
                            "        await google.colab.output.renderOutput(dataTable, element);\n",
                            "        const docLink = document.createElement('div');\n",
                            "        docLink.innerHTML = docLinkHtml;\n",
                            "        element.appendChild(docLink);\n",
                            "      }\n",
                            "    </script>\n",
                            "  </div>\n",
                            "  \n",
                            "    </div>\n",
                            "  </div>\n",
                            "  "
                        ],
                        "text/plain": [
                            "   unit_id  cycle  op_setting_1  op_setting_2  op_setting_3  sensor_1  \\\n",
                            "0        1      1       -0.0007       -0.0004         100.0    518.67   \n",
                            "1        1      2        0.0019       -0.0003         100.0    518.67   \n",
                            "2        1      3       -0.0043        0.0003         100.0    518.67   \n",
                            "3        1      4        0.0007        0.0000         100.0    518.67   \n",
                            "4        1      5       -0.0019       -0.0002         100.0    518.67   \n",
                            "\n",
                            "   sensor_2  sensor_3  sensor_4  sensor_5  ...  sensor_13  sensor_14  \\\n",
                            "0    641.82   1589.70   1400.60     14.62  ...    2388.02    8138.62   \n",
                            "1    642.15   1591.82   1403.14     14.62  ...    2388.07    8131.49   \n",
                            "2    642.35   1587.99   1404.20     14.62  ...    2388.03    8133.23   \n",
                            "3    642.35   1582.79   1401.87     14.62  ...    2388.08    8133.83   \n",
                            "4    642.37   1582.85   1406.22     14.62  ...    2388.04    8133.80   \n",
                            "\n",
                            "   sensor_15  sensor_16  sensor_17  sensor_18  sensor_19  sensor_20  \\\n",
                            "0     8.4195       0.03        392       2388      100.0      39.06   \n",
                            "1     8.4318       0.03        392       2388      100.0      39.00   \n",
                            "2     8.4178       0.03        390       2388      100.0      38.95   \n",
                            "3     8.3682       0.03        392       2388      100.0      38.88   \n",
                            "4     8.4294       0.03        393       2388      100.0      38.90   \n",
                            "\n",
                            "   sensor_21  RUL  \n",
                            "0    23.4190  125  \n",
                            "1    23.4236  125  \n",
                            "2    23.3442  125  \n",
                            "3    23.3739  125  \n",
                            "4    23.4044  125  \n",
                            "\n",
                            "[5 rows x 27 columns]"
                        ]
                    },
                    "execution_count": 4,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": [
                "import os\n",
                "import numpy as np\n",
                "import config\n",
                "from src.data.download import download_cmapss, load_cmapss_train\n",
                "from src.data.preprocess import DataPreprocessor\n",
                "from src.data.feature_engineering import FeatureEngineer\n",
                "from src.data.synthetic_generator import SyntheticDataGenerator\n",
                "\n",
                "# Download C-MAPSS dataset (direct URL, no auth)\n",
                "download_cmapss()\n",
                "df_train = load_cmapss_train()\n",
                "print(f\"\\nTraining data: {df_train.shape}\")\n",
                "df_train.head()"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 5,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "============================================================\n",
                        "Generating Synthetic Industrial Data\n",
                        "============================================================\n",
                        "[SYNTHETIC] Generated 444 maintenance logs for 100 units\n",
                        "  Planned: 292 | Unplanned: 152\n",
                        "  Total cost: $4,030,800\n",
                        "[SYNTHETIC] Generated operational context for 100 units\n",
                        "\n",
                        "[SYNTHETIC] All data saved to /content/Capstone-Project/data/synthetic\n",
                        "Maintenance logs: (444, 8)\n",
                        "Operational context: (100, 9)\n"
                    ]
                }
            ],
            "source": [
                "# Generate synthetic data\n",
                "gen = SyntheticDataGenerator()\n",
                "logs, context, schedule = gen.generate_all(df_train)\n",
                "print(f\"Maintenance logs: {logs.shape}\")\n",
                "print(f\"Operational context: {context.shape}\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 6,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "============================================================\n",
                        "Running Feature Engineering Pipeline\n",
                        "============================================================\n",
                        "[FEATURES] Added cycle_norm and cycle_squared features\n"
                    ]
                },
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "/content/Capstone-Project/src/data/feature_engineering.py:67: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
                        "  df[col_name] = series\n",
                        "/content/Capstone-Project/src/data/feature_engineering.py:67: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
                        "  df[col_name] = series\n",
                        "/content/Capstone-Project/src/data/feature_engineering.py:67: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
                        "  df[col_name] = series\n",
                        "/content/Capstone-Project/src/data/feature_engineering.py:67: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
                        "  df[col_name] = series\n",
                        "/content/Capstone-Project/src/data/feature_engineering.py:67: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
                        "  df[col_name] = series\n",
                        "/content/Capstone-Project/src/data/feature_engineering.py:67: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
                        "  df[col_name] = series\n",
                        "/content/Capstone-Project/src/data/feature_engineering.py:67: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
                        "  df[col_name] = series\n",
                        "/content/Capstone-Project/src/data/feature_engineering.py:67: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
                        "  df[col_name] = series\n",
                        "/content/Capstone-Project/src/data/feature_engineering.py:67: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
                        "  df[col_name] = series\n",
                        "/content/Capstone-Project/src/data/feature_engineering.py:67: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
                        "  df[col_name] = series\n",
                        "/content/Capstone-Project/src/data/feature_engineering.py:67: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
                        "  df[col_name] = series\n",
                        "/content/Capstone-Project/src/data/feature_engineering.py:67: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
                        "  df[col_name] = series\n",
                        "/content/Capstone-Project/src/data/feature_engineering.py:67: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
                        "  df[col_name] = series\n",
                        "/content/Capstone-Project/src/data/feature_engineering.py:67: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
                        "  df[col_name] = series\n",
                        "/content/Capstone-Project/src/data/feature_engineering.py:67: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
                        "  df[col_name] = series\n",
                        "/content/Capstone-Project/src/data/feature_engineering.py:67: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
                        "  df[col_name] = series\n",
                        "/content/Capstone-Project/src/data/feature_engineering.py:67: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
                        "  df[col_name] = series\n",
                        "/content/Capstone-Project/src/data/feature_engineering.py:67: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
                        "  df[col_name] = series\n",
                        "/content/Capstone-Project/src/data/feature_engineering.py:67: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
                        "  df[col_name] = series\n",
                        "/content/Capstone-Project/src/data/feature_engineering.py:67: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
                        "  df[col_name] = series\n",
                        "/content/Capstone-Project/src/data/feature_engineering.py:67: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
                        "  df[col_name] = series\n",
                        "/content/Capstone-Project/src/data/feature_engineering.py:67: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
                        "  df[col_name] = series\n",
                        "/content/Capstone-Project/src/data/feature_engineering.py:67: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
                        "  df[col_name] = series\n",
                        "/content/Capstone-Project/src/data/feature_engineering.py:67: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
                        "  df[col_name] = series\n",
                        "/content/Capstone-Project/src/data/feature_engineering.py:67: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
                        "  df[col_name] = series\n",
                        "/content/Capstone-Project/src/data/feature_engineering.py:67: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
                        "  df[col_name] = series\n",
                        "/content/Capstone-Project/src/data/feature_engineering.py:67: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
                        "  df[col_name] = series\n",
                        "/content/Capstone-Project/src/data/feature_engineering.py:67: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
                        "  df[col_name] = series\n",
                        "/content/Capstone-Project/src/data/feature_engineering.py:67: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
                        "  df[col_name] = series\n",
                        "/content/Capstone-Project/src/data/feature_engineering.py:67: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
                        "  df[col_name] = series\n",
                        "/content/Capstone-Project/src/data/feature_engineering.py:67: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
                        "  df[col_name] = series\n",
                        "/content/Capstone-Project/src/data/feature_engineering.py:67: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
                        "  df[col_name] = series\n",
                        "/content/Capstone-Project/src/data/feature_engineering.py:67: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
                        "  df[col_name] = series\n",
                        "/content/Capstone-Project/src/data/feature_engineering.py:67: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
                        "  df[col_name] = series\n",
                        "/content/Capstone-Project/src/data/feature_engineering.py:67: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
                        "  df[col_name] = series\n",
                        "/content/Capstone-Project/src/data/feature_engineering.py:67: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
                        "  df[col_name] = series\n",
                        "/content/Capstone-Project/src/data/feature_engineering.py:67: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
                        "  df[col_name] = series\n",
                        "/content/Capstone-Project/src/data/feature_engineering.py:67: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
                        "  df[col_name] = series\n",
                        "/content/Capstone-Project/src/data/feature_engineering.py:67: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
                        "  df[col_name] = series\n",
                        "/content/Capstone-Project/src/data/feature_engineering.py:67: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
                        "  df[col_name] = series\n",
                        "/content/Capstone-Project/src/data/feature_engineering.py:67: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
                        "  df[col_name] = series\n",
                        "/content/Capstone-Project/src/data/feature_engineering.py:67: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
                        "  df[col_name] = series\n",
                        "/content/Capstone-Project/src/data/feature_engineering.py:67: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
                        "  df[col_name] = series\n",
                        "/content/Capstone-Project/src/data/feature_engineering.py:67: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
                        "  df[col_name] = series\n",
                        "/content/Capstone-Project/src/data/feature_engineering.py:67: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
                        "  df[col_name] = series\n",
                        "/content/Capstone-Project/src/data/feature_engineering.py:67: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
                        "  df[col_name] = series\n",
                        "/content/Capstone-Project/src/data/feature_engineering.py:67: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
                        "  df[col_name] = series\n",
                        "/content/Capstone-Project/src/data/feature_engineering.py:67: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
                        "  df[col_name] = series\n",
                        "/content/Capstone-Project/src/data/feature_engineering.py:67: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
                        "  df[col_name] = series\n",
                        "/content/Capstone-Project/src/data/feature_engineering.py:67: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
                        "  df[col_name] = series\n",
                        "/content/Capstone-Project/src/data/feature_engineering.py:67: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
                        "  df[col_name] = series\n",
                        "/content/Capstone-Project/src/data/feature_engineering.py:67: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
                        "  df[col_name] = series\n",
                        "/content/Capstone-Project/src/data/feature_engineering.py:67: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
                        "  df[col_name] = series\n",
                        "/content/Capstone-Project/src/data/feature_engineering.py:67: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
                        "  df[col_name] = series\n",
                        "/content/Capstone-Project/src/data/feature_engineering.py:67: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
                        "  df[col_name] = series\n",
                        "/content/Capstone-Project/src/data/feature_engineering.py:67: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
                        "  df[col_name] = series\n",
                        "/content/Capstone-Project/src/data/feature_engineering.py:67: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
                        "  df[col_name] = series\n",
                        "/content/Capstone-Project/src/data/feature_engineering.py:67: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
                        "  df[col_name] = series\n",
                        "/content/Capstone-Project/src/data/feature_engineering.py:67: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
                        "  df[col_name] = series\n",
                        "/content/Capstone-Project/src/data/feature_engineering.py:67: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
                        "  df[col_name] = series\n",
                        "/content/Capstone-Project/src/data/feature_engineering.py:67: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
                        "  df[col_name] = series\n",
                        "/content/Capstone-Project/src/data/feature_engineering.py:67: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
                        "  df[col_name] = series\n",
                        "/content/Capstone-Project/src/data/feature_engineering.py:67: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
                        "  df[col_name] = series\n",
                        "/content/Capstone-Project/src/data/feature_engineering.py:67: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
                        "  df[col_name] = series\n",
                        "/content/Capstone-Project/src/data/feature_engineering.py:67: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
                        "  df[col_name] = series\n",
                        "/content/Capstone-Project/src/data/feature_engineering.py:67: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
                        "  df[col_name] = series\n",
                        "/content/Capstone-Project/src/data/feature_engineering.py:67: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
                        "  df[col_name] = series\n",
                        "/content/Capstone-Project/src/data/feature_engineering.py:67: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
                        "  df[col_name] = series\n",
                        "/content/Capstone-Project/src/data/feature_engineering.py:67: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
                        "  df[col_name] = series\n",
                        "/content/Capstone-Project/src/data/feature_engineering.py:67: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
                        "  df[col_name] = series\n",
                        "/content/Capstone-Project/src/data/feature_engineering.py:67: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
                        "  df[col_name] = series\n",
                        "/content/Capstone-Project/src/data/feature_engineering.py:67: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
                        "  df[col_name] = series\n"
                    ]
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "[FEATURES] Added 168 rolling features (3 windows √ó 4 stats √ó 14 sensors)\n"
                    ]
                },
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "/content/Capstone-Project/src/data/feature_engineering.py:106: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
                        "  df[col_name] = series\n",
                        "/content/Capstone-Project/src/data/feature_engineering.py:106: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
                        "  df[col_name] = series\n",
                        "/content/Capstone-Project/src/data/feature_engineering.py:106: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
                        "  df[col_name] = series\n",
                        "/content/Capstone-Project/src/data/feature_engineering.py:106: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
                        "  df[col_name] = series\n",
                        "/content/Capstone-Project/src/data/feature_engineering.py:106: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
                        "  df[col_name] = series\n",
                        "/content/Capstone-Project/src/data/feature_engineering.py:106: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
                        "  df[col_name] = series\n",
                        "/content/Capstone-Project/src/data/feature_engineering.py:106: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
                        "  df[col_name] = series\n",
                        "/content/Capstone-Project/src/data/feature_engineering.py:106: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
                        "  df[col_name] = series\n",
                        "/content/Capstone-Project/src/data/feature_engineering.py:106: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
                        "  df[col_name] = series\n",
                        "/content/Capstone-Project/src/data/feature_engineering.py:106: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
                        "  df[col_name] = series\n",
                        "/content/Capstone-Project/src/data/feature_engineering.py:106: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
                        "  df[col_name] = series\n",
                        "/content/Capstone-Project/src/data/feature_engineering.py:106: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
                        "  df[col_name] = series\n",
                        "/content/Capstone-Project/src/data/feature_engineering.py:106: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
                        "  df[col_name] = series\n",
                        "/content/Capstone-Project/src/data/feature_engineering.py:106: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
                        "  df[col_name] = series\n"
                    ]
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "[FEATURES] Added 14 trend features\n"
                    ]
                },
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "/content/Capstone-Project/src/data/feature_engineering.py:129: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
                        "  df[\"operating_regime\"] = self.regime_model.fit_predict(df[op_cols])\n",
                        "/content/Capstone-Project/src/data/feature_engineering.py:157: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
                        "  df[col_name] = np.nan\n",
                        "/content/Capstone-Project/src/data/feature_engineering.py:157: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
                        "  df[col_name] = np.nan\n",
                        "/content/Capstone-Project/src/data/feature_engineering.py:157: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
                        "  df[col_name] = np.nan\n",
                        "/content/Capstone-Project/src/data/feature_engineering.py:157: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
                        "  df[col_name] = np.nan\n",
                        "/content/Capstone-Project/src/data/feature_engineering.py:157: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
                        "  df[col_name] = np.nan\n",
                        "/content/Capstone-Project/src/data/feature_engineering.py:157: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
                        "  df[col_name] = np.nan\n",
                        "/content/Capstone-Project/src/data/feature_engineering.py:157: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
                        "  df[col_name] = np.nan\n",
                        "/content/Capstone-Project/src/data/feature_engineering.py:157: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
                        "  df[col_name] = np.nan\n",
                        "/content/Capstone-Project/src/data/feature_engineering.py:157: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
                        "  df[col_name] = np.nan\n",
                        "/content/Capstone-Project/src/data/feature_engineering.py:157: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
                        "  df[col_name] = np.nan\n",
                        "/content/Capstone-Project/src/data/feature_engineering.py:157: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
                        "  df[col_name] = np.nan\n",
                        "/content/Capstone-Project/src/data/feature_engineering.py:157: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
                        "  df[col_name] = np.nan\n",
                        "/content/Capstone-Project/src/data/feature_engineering.py:157: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
                        "  df[col_name] = np.nan\n",
                        "/content/Capstone-Project/src/data/feature_engineering.py:157: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
                        "  df[col_name] = np.nan\n",
                        "/content/Capstone-Project/src/data/feature_engineering.py:157: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
                        "  df[col_name] = np.nan\n",
                        "/content/Capstone-Project/src/data/feature_engineering.py:157: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
                        "  df[col_name] = np.nan\n",
                        "/content/Capstone-Project/src/data/feature_engineering.py:157: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
                        "  df[col_name] = np.nan\n",
                        "/content/Capstone-Project/src/data/feature_engineering.py:157: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
                        "  df[col_name] = np.nan\n",
                        "/content/Capstone-Project/src/data/feature_engineering.py:157: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
                        "  df[col_name] = np.nan\n",
                        "/content/Capstone-Project/src/data/feature_engineering.py:157: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
                        "  df[col_name] = np.nan\n",
                        "/content/Capstone-Project/src/data/feature_engineering.py:157: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
                        "  df[col_name] = np.nan\n",
                        "/content/Capstone-Project/src/data/feature_engineering.py:157: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
                        "  df[col_name] = np.nan\n",
                        "/content/Capstone-Project/src/data/feature_engineering.py:157: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
                        "  df[col_name] = np.nan\n",
                        "/content/Capstone-Project/src/data/feature_engineering.py:157: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
                        "  df[col_name] = np.nan\n",
                        "/content/Capstone-Project/src/data/feature_engineering.py:157: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
                        "  df[col_name] = np.nan\n",
                        "/content/Capstone-Project/src/data/feature_engineering.py:157: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
                        "  df[col_name] = np.nan\n",
                        "/content/Capstone-Project/src/data/feature_engineering.py:157: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
                        "  df[col_name] = np.nan\n",
                        "/content/Capstone-Project/src/data/feature_engineering.py:157: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
                        "  df[col_name] = np.nan\n",
                        "/content/Capstone-Project/src/data/feature_engineering.py:157: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
                        "  df[col_name] = np.nan\n",
                        "/content/Capstone-Project/src/data/feature_engineering.py:157: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
                        "  df[col_name] = np.nan\n",
                        "/content/Capstone-Project/src/data/feature_engineering.py:157: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
                        "  df[col_name] = np.nan\n",
                        "/content/Capstone-Project/src/data/feature_engineering.py:157: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
                        "  df[col_name] = np.nan\n",
                        "/content/Capstone-Project/src/data/feature_engineering.py:157: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
                        "  df[col_name] = np.nan\n",
                        "/content/Capstone-Project/src/data/feature_engineering.py:157: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
                        "  df[col_name] = np.nan\n",
                        "/content/Capstone-Project/src/data/feature_engineering.py:157: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
                        "  df[col_name] = np.nan\n",
                        "/content/Capstone-Project/src/data/feature_engineering.py:157: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
                        "  df[col_name] = np.nan\n",
                        "/content/Capstone-Project/src/data/feature_engineering.py:157: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
                        "  df[col_name] = np.nan\n",
                        "/content/Capstone-Project/src/data/feature_engineering.py:157: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
                        "  df[col_name] = np.nan\n",
                        "/content/Capstone-Project/src/data/feature_engineering.py:157: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
                        "  df[col_name] = np.nan\n",
                        "/content/Capstone-Project/src/data/feature_engineering.py:157: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
                        "  df[col_name] = np.nan\n",
                        "/content/Capstone-Project/src/data/feature_engineering.py:157: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
                        "  df[col_name] = np.nan\n",
                        "/content/Capstone-Project/src/data/feature_engineering.py:157: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
                        "  df[col_name] = np.nan\n"
                    ]
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "[FEATURES] Clustered 2 settings into 3 regimes:\n",
                        "  Regime 0: 5208 observations (25.2%)\n",
                        "  Regime 1: 5800 observations (28.1%)\n",
                        "  Regime 2: 9623 observations (46.6%)\n",
                        "[FEATURES] Added 42 lag features (3 lags √ó 14 sensors)\n",
                        "[FEATURES] Added 20 interaction features from top-5 sensors\n",
                        "\n",
                        "[FEATURES] Total features: 27 ‚Üí 274 (+247 engineered)\n",
                        "Engineered features: (20631, 274)\n"
                    ]
                },
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "/content/Capstone-Project/src/data/feature_engineering.py:163: FutureWarning: DataFrame.fillna with 'method' is deprecated and will raise in a future version. Use obj.ffill() or obj.bfill() instead.\n",
                        "  df[lag_cols] = df[lag_cols].fillna(method=\"bfill\").fillna(0)\n",
                        "/content/Capstone-Project/src/data/feature_engineering.py:183: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
                        "  df[f\"{s1}_x_{s2}\"] = df[s1] * df[s2]\n",
                        "/content/Capstone-Project/src/data/feature_engineering.py:184: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
                        "  df[f\"{s1}_div_{s2}\"] = df[s1] / (df[s2] + 1e-8)\n",
                        "/content/Capstone-Project/src/data/feature_engineering.py:183: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
                        "  df[f\"{s1}_x_{s2}\"] = df[s1] * df[s2]\n",
                        "/content/Capstone-Project/src/data/feature_engineering.py:184: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
                        "  df[f\"{s1}_div_{s2}\"] = df[s1] / (df[s2] + 1e-8)\n",
                        "/content/Capstone-Project/src/data/feature_engineering.py:183: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
                        "  df[f\"{s1}_x_{s2}\"] = df[s1] * df[s2]\n",
                        "/content/Capstone-Project/src/data/feature_engineering.py:184: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
                        "  df[f\"{s1}_div_{s2}\"] = df[s1] / (df[s2] + 1e-8)\n",
                        "/content/Capstone-Project/src/data/feature_engineering.py:183: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
                        "  df[f\"{s1}_x_{s2}\"] = df[s1] * df[s2]\n",
                        "/content/Capstone-Project/src/data/feature_engineering.py:184: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
                        "  df[f\"{s1}_div_{s2}\"] = df[s1] / (df[s2] + 1e-8)\n",
                        "/content/Capstone-Project/src/data/feature_engineering.py:183: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
                        "  df[f\"{s1}_x_{s2}\"] = df[s1] * df[s2]\n",
                        "/content/Capstone-Project/src/data/feature_engineering.py:184: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
                        "  df[f\"{s1}_div_{s2}\"] = df[s1] / (df[s2] + 1e-8)\n",
                        "/content/Capstone-Project/src/data/feature_engineering.py:183: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
                        "  df[f\"{s1}_x_{s2}\"] = df[s1] * df[s2]\n",
                        "/content/Capstone-Project/src/data/feature_engineering.py:184: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
                        "  df[f\"{s1}_div_{s2}\"] = df[s1] / (df[s2] + 1e-8)\n",
                        "/content/Capstone-Project/src/data/feature_engineering.py:183: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
                        "  df[f\"{s1}_x_{s2}\"] = df[s1] * df[s2]\n",
                        "/content/Capstone-Project/src/data/feature_engineering.py:184: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
                        "  df[f\"{s1}_div_{s2}\"] = df[s1] / (df[s2] + 1e-8)\n",
                        "/content/Capstone-Project/src/data/feature_engineering.py:183: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
                        "  df[f\"{s1}_x_{s2}\"] = df[s1] * df[s2]\n",
                        "/content/Capstone-Project/src/data/feature_engineering.py:184: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
                        "  df[f\"{s1}_div_{s2}\"] = df[s1] / (df[s2] + 1e-8)\n",
                        "/content/Capstone-Project/src/data/feature_engineering.py:183: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
                        "  df[f\"{s1}_x_{s2}\"] = df[s1] * df[s2]\n",
                        "/content/Capstone-Project/src/data/feature_engineering.py:184: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
                        "  df[f\"{s1}_div_{s2}\"] = df[s1] / (df[s2] + 1e-8)\n",
                        "/content/Capstone-Project/src/data/feature_engineering.py:183: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
                        "  df[f\"{s1}_x_{s2}\"] = df[s1] * df[s2]\n",
                        "/content/Capstone-Project/src/data/feature_engineering.py:184: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
                        "  df[f\"{s1}_div_{s2}\"] = df[s1] / (df[s2] + 1e-8)\n"
                    ]
                }
            ],
            "source": [
                "# Feature engineering (for XGBoost)\n",
                "fe = FeatureEngineer()\n",
                "df_engineered = fe.engineer_features(df_train.copy())\n",
                "print(f\"Engineered features: {df_engineered.shape}\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 7,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "============================================================\n",
                        "Running Full Preprocessing Pipeline\n",
                        "============================================================\n",
                        "[PREPROCESS] Dropped 9 constant columns: ['sensor_1', 'sensor_5', 'sensor_6', 'sensor_10', 'sensor_16', 'sensor_18', 'sensor_19', 'op_setting_3', 'op_setting_2']\n",
                        "[PREPROCESS] No missing values detected\n",
                        "[PREPROCESS] Split: train=70 units (14316 rows), val=15 units (3170 rows), test=15 units (3145 rows)\n",
                        "[PREPROCESS] Fitted scaler on 15 features\n",
                        "[PREPROCESS] Created 12286 sequences of shape (30, 15)\n",
                        "[PREPROCESS] train: X=(12286, 30, 15), y_rul range=[0, 125], failure_rate=17.66%\n",
                        "[PREPROCESS] Created 2735 sequences of shape (30, 15)\n",
                        "[PREPROCESS] val: X=(2735, 30, 15), y_rul range=[0, 125], failure_rate=17.00%\n",
                        "[PREPROCESS] Created 2710 sequences of shape (30, 15)\n",
                        "[PREPROCESS] test: X=(2710, 30, 15), y_rul range=[0, 125], failure_rate=17.16%\n",
                        "[PREPROCESS] Saved preprocessor to /content/Capstone-Project/models/saved/preprocessor.pkl\n",
                        "Sequences: (12286, 30, 15), Features: 15\n"
                    ]
                }
            ],
            "source": [
                "# Preprocessing pipeline (for LSTM models)\n",
                "preprocessor = DataPreprocessor()\n",
                "data = preprocessor.fit_transform(df_train)\n",
                "preprocessor.save()\n",
                "\n",
                "for split_name, split_data in data.items():\n",
                "    np.savez_compressed(\n",
                "        os.path.join(config.PROCESSED_DATA_DIR, f\"{split_name}_data.npz\"),\n",
                "        **split_data\n",
                "    )\n",
                "\n",
                "X_train = data['train']['X']\n",
                "y_train_rul = data['train']['y_rul']\n",
                "y_train_binary = data['train']['y_binary']\n",
                "X_val = data['val']['X']\n",
                "y_val_binary = data['val']['y_binary']\n",
                "\n",
                "n_features = X_train.shape[2]\n",
                "print(f\"Sequences: {X_train.shape}, Features: {n_features}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 3. Train LSTM Autoencoder (Anomaly Detection)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 8,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Training autoencoder on 7876 healthy samples\n",
                        "Device: cuda\n"
                    ]
                },
                {
                    "ename": "TypeError",
                    "evalue": "ReduceLROnPlateau.__init__() got an unexpected keyword argument 'verbose'",
                    "output_type": "error",
                    "traceback": [
                        "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
                        "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
                        "\u001b[0;32m/tmp/ipython-input-879921679.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0mautoencoder\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mLSTMAutoencoder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_dim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mn_features\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m \u001b[0mae_trainer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mAutoencoderTrainer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mautoencoder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m50\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m \u001b[0mae_trainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_healthy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_val_ae\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0mae_trainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
                        "\u001b[0;32m/content/Capstone-Project/src/models/autoencoder.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, model, lr, epochs, batch_size)\u001b[0m\n\u001b[1;32m    162\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbatch_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch_size\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mAE_BATCH_SIZE\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    163\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mAdam\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 164\u001b[0;31m         self.scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(\n\u001b[0m\u001b[1;32m    165\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpatience\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfactor\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    166\u001b[0m         )\n",
                        "\u001b[0;31mTypeError\u001b[0m: ReduceLROnPlateau.__init__() got an unexpected keyword argument 'verbose'"
                    ]
                }
            ],
            "source": [
                "from src.models.autoencoder import LSTMAutoencoder, AutoencoderTrainer\n",
                "\n",
                "# Train on healthy data only\n",
                "healthy_mask = y_train_rul > config.MAX_RUL * 0.5\n",
                "X_healthy = X_train[healthy_mask]\n",
                "X_val_ae = X_val[data['val']['y_rul'] > config.MAX_RUL * 0.5]\n",
                "\n",
                "print(f\"Training autoencoder on {len(X_healthy)} healthy samples\")\n",
                "print(f\"Device: {config.DEVICE}\")\n",
                "\n",
                "autoencoder = LSTMAutoencoder(input_dim=n_features)\n",
                "ae_trainer = AutoencoderTrainer(autoencoder, epochs=50)\n",
                "ae_trainer.train(X_healthy, X_val_ae)\n",
                "ae_trainer.save_model()"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Visualize training loss\n",
                "import matplotlib.pyplot as plt\n",
                "\n",
                "fig, ax = plt.subplots(figsize=(10, 4))\n",
                "ax.plot(ae_trainer.train_history, label='Train Loss', color='#3a7bd5')\n",
                "if ae_trainer.val_history:\n",
                "    ax.plot(ae_trainer.val_history, label='Val Loss', color='#FF6B6B')\n",
                "ax.set_xlabel('Epoch')\n",
                "ax.set_ylabel('MSE Loss')\n",
                "ax.set_title('Autoencoder Training')\n",
                "ax.legend()\n",
                "ax.grid(True, alpha=0.3)\n",
                "plt.tight_layout()\n",
                "plt.show()"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 4. Train LSTM Failure Predictor"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "from src.models.lstm_predictor import LSTMPredictor, PredictorTrainer\n",
                "\n",
                "predictor = LSTMPredictor(input_dim=n_features)\n",
                "pred_trainer = PredictorTrainer(predictor, epochs=50)\n",
                "pred_trainer.train(X_train, y_train_binary, X_val, y_val_binary)\n",
                "pred_trainer.save_model()"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Visualize predictor training\n",
                "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(14, 4))\n",
                "\n",
                "ax1.plot(pred_trainer.train_history, label='Train Loss', color='#3a7bd5')\n",
                "ax1.set_xlabel('Epoch')\n",
                "ax1.set_ylabel('Loss')\n",
                "ax1.set_title('Predictor Training Loss')\n",
                "ax1.legend()\n",
                "ax1.grid(True, alpha=0.3)\n",
                "\n",
                "if pred_trainer.val_history:\n",
                "    epochs_list = range(5, len(pred_trainer.val_history) * 5 + 1, 5)\n",
                "    f1s = [m.get('f1', 0) for m in pred_trainer.val_history]\n",
                "    aucs = [m.get('auc', 0) for m in pred_trainer.val_history]\n",
                "    ax2.plot(epochs_list, f1s, label='F1 Score', color='#44BB44', marker='o', markersize=4)\n",
                "    ax2.plot(epochs_list, aucs, label='AUC', color='#FF6B6B', marker='s', markersize=4)\n",
                "    ax2.set_xlabel('Epoch')\n",
                "    ax2.set_ylabel('Score')\n",
                "    ax2.set_title('Validation Metrics')\n",
                "    ax2.legend()\n",
                "    ax2.grid(True, alpha=0.3)\n",
                "\n",
                "plt.tight_layout()\n",
                "plt.show()"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 5. Train XGBoost RUL Model"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "from src.models.xgboost_rul import XGBoostRUL\n",
                "\n",
                "exclude_cols = ['unit_id', 'cycle', 'RUL']\n",
                "feature_cols = [c for c in df_engineered.columns if c not in exclude_cols]\n",
                "\n",
                "unit_ids = df_engineered['unit_id'].unique()\n",
                "np.random.seed(config.RANDOM_SEED)\n",
                "np.random.shuffle(unit_ids)\n",
                "n = len(unit_ids)\n",
                "train_units = unit_ids[:int(n * 0.7)]\n",
                "val_units = unit_ids[int(n * 0.7):int(n * 0.85)]\n",
                "\n",
                "X_train_xgb = df_engineered[df_engineered['unit_id'].isin(train_units)][feature_cols]\n",
                "y_train_xgb = df_engineered[df_engineered['unit_id'].isin(train_units)]['RUL'].values\n",
                "X_val_xgb = df_engineered[df_engineered['unit_id'].isin(val_units)][feature_cols]\n",
                "y_val_xgb = df_engineered[df_engineered['unit_id'].isin(val_units)]['RUL'].values\n",
                "\n",
                "xgb_model = XGBoostRUL()\n",
                "xgb_model.train(X_train_xgb, y_train_xgb, X_val_xgb, y_val_xgb,\n",
                "                feature_names=feature_cols)\n",
                "xgb_model.evaluate(X_val_xgb, y_val_xgb)\n",
                "xgb_model.save()"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 6. Bayesian Survival Analysis"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "from src.models.bayesian_survival import BayesianSurvival\n",
                "\n",
                "survival_features = config.ACTIVE_SENSORS + ['cycle']\n",
                "survival_cols = [c for c in survival_features if c in df_train.columns] + ['RUL']\n",
                "\n",
                "df_survival_train = df_train[df_train['unit_id'].isin(train_units)][['unit_id'] + survival_cols]\n",
                "\n",
                "survival_model = BayesianSurvival()\n",
                "survival_model.fit(df_survival_train)\n",
                "\n",
                "df_survival_val = df_train[df_train['unit_id'].isin(val_units)][['unit_id'] + survival_cols]\n",
                "survival_model.evaluate(df_survival_val)\n",
                "survival_model.save()"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 7. Explainability (SHAP & Attention)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "from src.explainability.shap_analysis import SHAPExplainer\n",
                "\n",
                "# SHAP for XGBoost\n",
                "shap_explainer = SHAPExplainer(xgb_model, model_type='xgboost')\n",
                "shap_explainer.compute_shap_values(X_val_xgb)\n",
                "shap_explainer.plot_global_importance(save_path='shap_importance.png')\n",
                "shap_explainer.plot_beeswarm(save_path='shap_beeswarm.png')\n",
                "ranking = shap_explainer.get_sensor_ranking()\n",
                "ranking.head(15)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "from src.explainability.attention_viz import AttentionVisualizer\n",
                "\n",
                "# Attention visualization\n",
                "attn_viz = AttentionVisualizer(predictor)\n",
                "attn_viz.plot_attention_heatmap(data['test']['X'], save_path='attention_heatmap.png')\n",
                "attn_viz.plot_average_attention(data['test']['X'], data['test']['y_binary'],\n",
                "                                save_path='attention_comparison.png')"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 8. MILP Optimization & Simulation"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "from src.optimization.milp_scheduler import MaintenanceScheduler\n",
                "\n",
                "# Get predictions for test data\n",
                "failure_proba, _ = predictor.predict_proba(torch.FloatTensor(data['test']['X']).to(config.DEVICE))\n",
                "\n",
                "# Aggregate per unit\n",
                "unit_risks = {}\n",
                "for uid in np.unique(data['test']['unit_ids']):\n",
                "    mask = data['test']['unit_ids'] == uid\n",
                "    unit_risks[int(uid)] = float(failure_proba[mask][-1])\n",
                "\n",
                "# Run MILP optimization\n",
                "scheduler = MaintenanceScheduler()\n",
                "result = scheduler.create_schedule(\n",
                "    machine_risks=unit_risks,\n",
                "    machine_names={uid: f'Engine-{uid:03d}' for uid in unit_risks}\n",
                ")\n",
                "result['schedule']"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Monte Carlo simulation\n",
                "from src.evaluation.simulation import MaintenanceSimulator\n",
                "\n",
                "sim = MaintenanceSimulator(n_machines=50, n_periods=100)\n",
                "sim_df, sim_summary = sim.run_comparison(n_simulations=100)\n",
                "sim.plot_comparison(sim_df, save_path='simulation_comparison.png')"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 9. Download Results\n",
                "\n",
                "Download trained models and results back to local machine."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Save all results to a zip for download\n",
                "import shutil\n",
                "shutil.make_archive('capstone_results', 'zip', '.', 'models/saved')\n",
                "\n",
                "# In Colab, download the zip:\n",
                "try:\n",
                "    from google.colab import files\n",
                "    files.download('capstone_results.zip')\n",
                "except ImportError:\n",
                "    print('Not in Colab. Files saved locally.')"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "---\n",
                "**Project**: FSE 570 Data Science Capstone | Arizona State University"
            ]
        }
    ],
    "metadata": {
        "accelerator": "GPU",
        "kernelspec": {
            "display_name": "Python 3 (ipykernel)",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.12.12"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 4
}
